{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elements of Convex Optimization 2024 - Project\n",
    "\n",
    "### Solution author: <name, index>\n",
    "\n",
    "This notebook uses helper classes and functions defined in [eco_project_helpers](eco_project_helpers) file, but there is no need to look at it.\n",
    "\n",
    "This project requires **numpy**, **matplotlib**, **seaborn** and **[autograd](https://github.com/HIPS/autograd)** libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib seaborn autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "The task is to implement an optimization algorithm that can deal with non-convex, multi-modal functions that are differentiable and smooth over the entire domain. Functions can have a varying number of arguments (more than 2). The quality of the solution is measured by the success rate of finding the global minimum of the function in a given budget of function (or gradient/Hessian) evaluations. The final grades will be calculated relative to the best-submitted solution. The best solution will be awarded with bonus points (+10 bonus percent point to the final grade)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark functions\n",
    "\n",
    "Below, you can find a few example benchmark functions. \n",
    "Please be aware that the final evaluation functions, which may have more than two arguments, could be more complex than the examples provided. These examples are a good starting point for testing your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from eco_project_helpers import BENCHMARK_FUNCTIONS, BenchmarkFunction\n",
    "\n",
    "\n",
    "def plot_function_2d(f: BenchmarkFunction):\n",
    "    if f.N == 2: # Plot only if function is 2D\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        x = np.linspace(f.bounds[0][0], f.bounds[0][1], 100)\n",
    "        y = np.linspace(f.bounds[1][0], f.bounds[1][1], 100)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.array([[f.func(np.array([x, y])) for x, y in zip(x, y)] for x, y in zip(X, Y)])\n",
    "        ax.plot_surface(X, Y, Z, cmap=sns.color_palette(\"flare\", as_cmap=True))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def check_grad_and_hessian(f: BenchmarkFunction):\n",
    "    x_1 = np.linspace(f.bounds[0][0], f.bounds[0][1], 100)\n",
    "    x_2 = np.linspace(f.bounds[1][0], f.bounds[1][1], 100)\n",
    "    for x_1_i in x_1:\n",
    "        for x_2_i in x_2:\n",
    "            x = np.array([x_1_i, x_2_i])\n",
    "            grad = f.grad(x)\n",
    "            H = f.hess(x)\n",
    "            if np.isnan(grad).any() or np.isnan(H).any():\n",
    "                print(f\"NaN gradient or Hessian at {x}\")\n",
    "                return\n",
    "\n",
    "\n",
    "for func_class in BENCHMARK_FUNCTIONS:\n",
    "    f = func_class(budget=None)\n",
    "    print(f\"Function: {f.__class__.__name__}\")\n",
    "    print(f\"Dimensions: {f.N}\")\n",
    "    print(f\"Bounds: {f.bounds}\")\n",
    "    plot_function_2d(f)\n",
    "    check_grad_and_hessian(f) # This may take some time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example implementations of naive solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sampling(f: BenchmarkFunction):\n",
    "    best_val = np.inf\n",
    "    best_x = None\n",
    "    while f.budget_left:\n",
    "        x = np.random.uniform(f.xmin, f.xmax)\n",
    "        val = f.func(x)\n",
    "\n",
    "        if val < best_val:\n",
    "            best_val = val\n",
    "            best_x = x\n",
    "\n",
    "    return best_x\n",
    "\n",
    "\n",
    "def naive_gradient_descent(f: BenchmarkFunction):\n",
    "    start_learnign_rate = 0.1\n",
    "    x = np.random.uniform(f.xmin, f.xmax) # Random initial point\n",
    "    budget = f.budget_left\n",
    "    for i in range(budget):\n",
    "        lr = start_learnign_rate * (budget - i) / budget # Linearly decrease learning rate\n",
    "        grad = f.grad(x)\n",
    "        new_x = x - lr * grad\n",
    "\n",
    "        # Only move to new point if it is within bounds\n",
    "        if np.all(new_x >= f.xmin) and np.all(new_x <= f.xmax):\n",
    "            x = new_x\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Your solution will be evaluated similarly to the code below. The evaluation will be done on a set of benchmark functions that are not presented here. The x returned by the function will be compared to the global minimum of the function. The returned x will be considered the global minimum if the value of the function in x is less than 1e-5, then the value of the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "\n",
    "def eval_optimization_method(\n",
    "        opt_f: Callable[[BenchmarkFunction], np.ndarray], \n",
    "        benchmarks: List[BenchmarkFunction], \n",
    "        budget: int = 1000, \n",
    "        repetitions: int = 10               \n",
    "    ):\n",
    "    for func_class in benchmarks:\n",
    "        success_rate = 0\n",
    "        for _ in range(repetitions):\n",
    "            f = func_class(budget=budget)\n",
    "            x = opt_f(f)\n",
    "            if f.success(x):\n",
    "                success_rate += 1\n",
    "        success_rate /= repetitions\n",
    "        print(f\"Success rate of {opt_f.__name__}({f.__class__.__name__}(budget={budget})) = {success_rate}\")\n",
    "\n",
    "eval_optimization_method(random_sampling, BENCHMARK_FUNCTIONS, budget=1000)\n",
    "eval_optimization_method(naive_gradient_descent, BENCHMARK_FUNCTIONS, budget=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your solution\n",
    "\n",
    "Implement your solution below. DO NOT change the name of the function, and DO NOT add positional arguments to it (keyword arguments with default values are ok), as it will be graded and evaluated automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_global_optimization_algorithm(f: BenchmarkFunction):\n",
    "    # All available tools:\n",
    "    dim = f.N # Number of input dimensions (function arguments)\n",
    "    x = np.random.uniform(f.xmin, f.xmax)\n",
    "    budget = f.budget_left # Remaining budget\n",
    "\n",
    "    val = f.func(x) # Evaluate function at x, reduce budget by 1\n",
    "    grad = f.grad(x) # Evaluate gradient at x, reduce budget by 1\n",
    "    H = f.hess(x) # Evaluate Hessian at x, reduce budget by 1\n",
    "\n",
    "    # You implement this here\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips: \n",
    "- Check how your function performs on the benchmark functions with different budgets (e.g., 100, 500, 1000, 2000). \n",
    "- Use a large number of repetitions to get a better estimate of the success rate of your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_optimization_method(my_global_optimization_algorithm, BENCHMARK_FUNCTIONS, budget=1000, repetitions=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
